# 🔺 3-Agent Debate: Modeling Lead × Product Lead × Tech Lead (10 Rounds)

> **대상 문서**: [`implementation_plan.md (v4)`](file:///Users/sangwook/Documents/workspace/repo/antigravity_test/blackup_bean_order/docs/specs/implementation_plan.md)
> **참여 에이전트**:
> - 🤖 **Modeling Lead** — Principal AI Modeling Engineer: 모델/AI 기술 타당성, 추론 효율성, 평가 지표
> - 📋 **Product Lead** — Principal Product Manager: 사용자 가치, 비즈니스 지속 가능성, UX 흐름
> - ⚙️ **Tech Lead** — Distinguished Systems Engineer: 시스템 안정성, 확장성, 기술 부채

---

## Round 1: LLM 에이전트의 "집계" 업무 적합성 — 이건 AI가 할 일인가?

### 🤖 Modeling Lead 비판

> **[Model-Product Fit: CRITICAL MISMATCH]**
>
> 이 시스템의 핵심 업무는 **표 데이터 읽기 → 숫자 합산 → 정형 리포트 출력**이다. 이것은 **LLM이 해야 할 일이 아니다.**
>
> 1. **환각(Hallucination) 리스크**: LLM은 숫자 계산에서 오류를 낼 수 있다. "5 + 3 + 8 = 16"을 "15"로 출력하면? 교차검증이 있지만, 검증 자체도 같은 LLM이 수행한다. **AI가 산수를 틀리는 리스크를 왜 감수하는가?**
> 2. **토큰 낭비**: 3개 매장 × 10건 주문을 처리하는 데 수천~수만 토큰을 소모한다. 같은 작업을 Python 스크립트가 0.1초에, 토큰 0개로 수행 가능하다. **Inference Efficiency가 최악**이다.
> 3. **Code Interpreter 미활용**: 에이전트에 코드 실행 능력이 있다면, SKILL.md에 "Python으로 집계하라"고 지시하는 것이 LLM의 자연어 집계보다 **100% 정확하고 100배 빠르다.**
>
> **판정: Model-Product Fit = ❌ 부적합** — 이것은 AI 문제가 아니라 **데이터 처리 자동화 문제**다.

### 📋 Product Lead 반론

> **[10x Value Check]**
>
> Modeling Lead의 이론적 분석은 맞지만, **"누가 쓰는가"를 무시**하고 있다:
>
> 1. **Python 스크립트 = 사용 불가**: 타겟 사용자(로스터리 사장님)에게 Python은 외국어다. "pip install pandas" 시점에 프로젝트는 사망한다.
> 2. **LLM의 진짜 가치**: 단순 합산이 아니라 **비정형 데이터 대응**이다. 매장이 시트를 약간 다르게 쓰더라도 에이전트가 맥락을 이해하고 처리한다. 스크립트는 `KeyError`를 뱉는다.
> 3. **10x Value = 접근성**: 기술적 최적해가 아니라 **사용자 접근 가능한 최선해**를 추구한다.

### ⚙️ Tech Lead 중재

> **[Tech Debt Assessment]**
>
> 둘 다 일리가 있다. **하이브리드 접근**을 제안한다:
>
> - SKILL.md에 "**숫자 집계는 에이전트 내부 코드 실행(Code Interpreter)으로 수행**하고, 리포트 형식화와 비정형 데이터 해석만 LLM이 담당"하도록 역할 분리를 명시한다.
> - 이렇게 하면 Hallucination 리스크 제거 + LLM 유연성 유지가 가능하다.

### ✅ 결정: **Modeling Lead 부분 승리 — 즉시 반영**

- SKILL.md에 **"숫자 집계 시 코드 실행 우선 원칙"** 추가
- "수량 합산, 검증 비교 등 산술 연산은 코드로 수행. 데이터 해석, 리포트 문장 생성은 LLM 담당"
- 역할 분리로 Hallucination 리스크 최소화

---

## Round 2: 교차검증의 평가 지표 — "맞다/틀리다"만으로 충분한가?

### 🤖 Modeling Lead 비판

> **[Eval & Safety: INSUFFICIENT]**
>
> 교차검증 14개 항목이 모두 **이진 판정(✅/❌)**이다. AI 시스템에는 **정량적 평가 지표(Evaluation Metrics)**가 필요하다:
>
> 1. **Precision / Recall이 없다**: 중복 주문 감지의 **정확도**가 몇 %인지 측정하지 않는다. False Positive(실제로는 정상인데 중복 경고)와 False Negative(실제 중복인데 누락)의 비율은?
> 2. **Confidence Score 없음**: 미등록 원두 감지 시, 에이전트가 "오타일 수도 있다"는 판단에 **얼마나 확신하는지** 수치로 표현되지 않는다.
> 3. **누적 품질 추적 불가**: 매일 실행하면서 "이번 주 검증 통과율 95%"같은 **시계열 품질 지표**가 없다.

### 📋 Product Lead 반론

> **[KPI Definition]**
>
> 이론적으로 맞지만, **과잉 모니터링**이다:
>
> 1. 이 시스템은 일일 10~20건 처리하는 **마이크로 스케일**이다. Precision/Recall을 계산하려면 **Ground Truth(정답 라벨)**가 필요한데, 누가 매일 정답을 만드는가?
> 2. 그러나 **리포트 정확도 체감 지표**는 필요하다. 관리자가 리포트를 보고 수정한 횟수를 비공식적으로 추적하면 사용자 체감 품질로 쓸 수 있다.

### ⚙️ Tech Lead 중재

> **[Monitoring Strategy]**
>
> 간단한 지표부터 시작하자:
>
> - 리포트 메타데이터에 **"경고 발생 건수"**를 누적 표시: "이번 주 총 경고: 3건 (⚠️ 2건, ℹ️ 1건)"
> - v1.5에서 `reports/` 폴더의 과거 리포트를 스캔하여 **주간 품질 요약** 자동 생성

### ✅ 결정: **부분 수용**

- 리포트 메타데이터에 **경고 발생 건수 요약** 추가 (v1)
- v1.5에서 **주간 품질 요약** 자동 생성 검토
- Precision/Recall 본격 추적은 v2 scope (Ground Truth 확보 후)

---

## Round 3: 데이터 파이프라인 병목 — 브라우저 순회의 실제 성능

### ⚙️ Tech Lead 비판

> **[Bottleneck Analysis: HIGH]**
>
> 브라우저로 Google Sheets를 순회하는 것의 **실제 성능**을 분석한다:
>
> 1. **매장당 소요 시간**: 브라우저 열기 → 로그인 확인 → 페이지 로드 → DOM 파싱 ≈ **10~30초**/매장. 5개 매장이면 1~3분.
> 2. **직렬 처리**: 브라우저 도구는 한 번에 1개 URL만 접근 가능. **병렬 처리 불가**로 매장 수에 정비례하는 선형 시간.
> 3. **타임아웃 미정의**: 에이전트 컨텍스트 윈도우에 제한이 있다. 10개 매장 × 50건 주문의 데이터가 컨텍스트에 들어가는가? **토큰 초과 시 어떻게 하는가?**

### 🤖 Modeling Lead 보강

> **[Inference Efficiency]**
>
> Tech Lead의 지적에 추가한다:
>
> 1. **컨텍스트 윈도우 관리**: 모든 매장 데이터를 한꺼번에 컨텍스트에 넣으면 토큰 제한에 걸린다. **매장별 청크(Chunk) 처리** → 중간 집계 → 최종 합산 전략이 필요하다.
> 2. 이것은 AI의 **RAG 패턴**과 유사하다: 전체 데이터를 한 번에 처리하지 말고, 청크 단위로 처리 + 어그리게이션.

### 📋 Product Lead 반론

> **[User Flow Audit]**
>
> 성능이 3분이면 **충분**하다. 관리자가 커피를 내리고 돌아오면 리포트가 완성되어 있는 수준. 수작업 60분 대비 3분은 **20x 가치**다. 단, 10개 매장 이상으로 늘어날 경우를 대비한 가이드는 있어야 한다.

### ✅ 결정: **수용 — 즉시 반영**

- SKILL.md에 **"매장별 순차 처리 + 중간 집계 전략"** 명시:
  - 매장 1 데이터 읽기 → 중간 집계 저장 → 매장 2 데이터 읽기 → 중간 집계 업데이트 → ... → 최종 합산
- SKILL.md에 **대규모 처리 가이드**: "8개 매장 이상은 2개 그룹으로 분할 처리 권장"
- 리포트 메타데이터에 **매장별 처리 시간** 추가 검토 (v1.5)

---

## Round 4: 프롬프트 엔지니어링 없는 SKILL.md — AI 가이드인가, 사람 가이드인가?

### 🤖 Modeling Lead 비판

> **[Model-Product Fit: DESIGN FLAW]**
>
> SKILL.md가 **사람이 읽는 매뉴얼 형태**로 작성되어 있다. 에이전트가 실행하는 지시서라면 **프롬프트 엔지니어링 원칙**이 적용되어야 한다:
>
> 1. **역할(Role) 미정의**: SKILL.md에 "너는 원두 주문 관리 에이전트다"라는 시스템 프롬프트가 없다. 에이전트의 정체성이 모호하면 출력 품질이 불안정하다.
> 2. **출력 형식 강제 부재**: "리포트를 Markdown으로 출력하라"지만, **정확한 테이블 구조, 컬럼 순서, 네이밍**을 Few-shot 예시로 보여주지 않는다.
> 3. **Chain-of-Thought 미활용**: 복잡한 검증 로직에서 "하나씩 확인하라"는 지시가 없다. LLM은 명시적으로 단계별 사고를 요청해야 정확도가 올라간다.
> 4. **가드레일 미설계**: 에이전트가 확신 없으면 "모르겠다"고 말해야 하는데, 이 프로토콜이 없다. 확신 없이 추측으로 리포트를 생성하면 **Hallucination → 잘못된 생산 계획**으로 이어진다.

### 📋 Product Lead 반론

> **[User Flow Audit]**
>
> SKILL.md가 사람 가독성도 있어야 관리자가 "에이전트가 뭘 하는지" 이해한다. 그러나 Modeling Lead의 프롬프트 엔지니어링 원칙은 **출력 품질 직결**이므로 반대할 이유가 없다.

### ⚙️ Tech Lead 보강

> **[Reliability]**
>
> 특히 **가드레일**에 동의한다. 에이전트가 시트 데이터를 해석할 수 없을 때 "추측으로 채우기"는 Silent Failure의 근원이다. "확신 없으면 해당 행 건너뛰기 + 경고"가 맞다.

### ✅ 결정: **Modeling Lead 승리 — 즉시 반영**

- SKILL.md 상단에 **에이전트 역할 정의** 추가:
  ```
  ## 에이전트 역할
  너는 블랙업 커피 로스터스의 원두 주문 관리 에이전트다.
  정확하고 일관된 리포트 생성이 핵심 임무다.
  ```
- **Few-shot 예시** 강화: 리포트 테이블의 정확한 구조를 예시로 제공
- **단계별 처리 지시**: "각 매장 데이터를 읽은 후, 하나씩 검증하라"
- **가드레일 규칙**: "데이터 해석이 불확실하면 해당 행을 건너뛰고 `⚠️ 해석 불가` 경고 표시"

---

## Round 5: 보안 — Google 계정 세션의 위험성

### ⚙️ Tech Lead 비판

> **[Security & Reliability: HIGH]**
>
> 브라우저 기반 인증은 "API 키 노출 위험 제로"라고 했는데, **다른 보안 리스크**가 있다:
>
> 1. **세션 하이재킹**: 에이전트가 사용하는 브라우저 세션에 Google 계정이 로그인되어 있다. 이 세션이 탈취되면 Sheets뿐 아니라 **Gmail, Drive, 결제 정보 등 전체 계정**이 노출된다.
> 2. **최소 권한 원칙 위반**: Sheets만 읽으면 되는데, 전체 Google 계정 세션을 사용한다. API + 서비스 계정이라면 **Sheets 읽기 권한만** 부여 가능하다.
> 3. **세션 지속 관리**: 브라우저 세션의 OAuth 토큰 갱신, 2FA 재인증 등을 에이전트가 처리할 수 있는가?

### 🤖 Modeling Lead 보강

> **[Safety]**
>
> AI 에이전트에 브라우저 전체 제어권을 주는 것은 AI Safety 관점에서도 위험하다. "에이전트가 의도치 않게 시트 데이터를 삭제하는" 시나리오에 대한 **세이프가드**가 필요하다.

### 📋 Product Lead 반론

> **[10x Value Check]**
>
> 보안 우려는 타당하나, **현실적 위험 수준을 평가**해야 한다:
>
> 1. 에이전트는 **로컬 머신**에서 실행된다. 세션 탈취는 머신 자체가 해킹되어야 가능하다.
> 2. 읽기 전용 워크플로우 — 에이전트는 Sheets에 **쓰지 않는다.** SKILL.md에 "읽기 전용" 원칙을 명시하면 실수 방지 가능.
> 3. **전용 Google 계정 사용 권장**: 관리자 개인 계정이 아닌, "주문관리용 계정"을 별도 생성하여 Sheets 읽기 권한만 공유하면 된다.

### ✅ 결정: **수용 — 즉시 반영**

- SKILL.md에 **보안 가이드** 추가:
  - "에이전트용 전용 Google 계정 사용 권장"
  - "에이전트는 읽기 전용 — 어떤 경우에도 원본 Sheets에 쓰기 금지"
- settings.yaml에 **`read_only: true`** 플래그 추가 (명시적 원칙)
- v2 로드맵: Google Sheets API + 서비스 계정 전환 시 최소 권한 적용

---

## Round 6: 리포트 출력의 일관성 — 매번 다르면 신뢰가 깨진다

### 🤖 Modeling Lead 비판

> **[Eval & Safety: CONSISTENCY RISK]**
>
> 에이전트가 매일 리포트를 생성하는데, **같은 입력에 같은 출력이 보장되지 않는다:**
>
> 1. **Temperature 미설정**: LLM의 temperature가 0보다 높으면, 동일 데이터에 대해 테이블 순서, 문구, 소수점 표기 등이 매번 달라질 수 있다.
> 2. **형식 드리프트(Format Drift)**: 시간이 지남에 따라 에이전트가 출력하는 리포트 형식이 서서히 바뀔 수 있다. 컬럼명이 "총 수량(kg)"에서 "총 주문량(kg)"으로 바뀌면 자동화된 후속 처리(v2의 트렌드 분석 등)가 깨진다.
> 3. **출력 스키마 검증 없음**: 생성된 리포트가 기대 형식과 일치하는지 **자동 검증하는 메커니즘**이 없다.

### 📋 Product Lead 반론

> **[User Flow Audit]**
>
> 일관성 문제는 인정한다. 비개발자 관리자도 "어제 리포트와 형식이 다르면" 불안을 느낀다. 해결 방안:
>
> 1. SKILL.md에 리포트 **정확한 Markdown 구조를 Template Literal로 선언**
> 2. 변동 부분(숫자, 매장명)만 에이전트가 채우는 **Mad-libs 패턴**

### ⚙️ Tech Lead 보강

> **[Reliability]**
>
> `templates/daily_report.md`가 이미 있으니, SKILL.md에서 "이 템플릿의 구조를 **절대 변경하지 말고**, 값만 채워 넣어라"고 강제하면 된다.

### ✅ 결정: **Modeling Lead 승리 — 즉시 반영**

- SKILL.md에 **"출력 형식 고정 원칙"** 추가:
  - "templates/daily_report.md의 구조를 정확히 따르라. 컬럼명, 순서, 포맷 변경 금지"
  - "숫자는 소수점 첫째 자리까지, 단위(kg) 항상 표기"
- `templates/daily_report.md`를 **스켈레톤 템플릿**으로 강화 (실제 빈 칸이 있는 형태)
- 교차검증에 **"리포트 형식 검증"** 항목 추가 (컬럼명, 섹션 순서 일치)

---

## Round 7: settings.yaml의 원두 마스터 데이터 — 누가 관리하는가?

### 📋 Product Lead 비판

> **[User Flow Audit: PAIN POINT]**
>
> 신규 원두 추가 시 사용자 여정을 보자:
>
> 1. 매장이 새 원두를 주문 → 미등록 경고 발생
> 2. 관리자가 settings.yaml을 열어 beans 목록에 추가
> 3. YAML 문법 실수 → 에이전트 오류 → 패닉
>
> **비개발자가 YAML을 편집하는 것 자체가 UX 실패**다. 이 과정이 **매번 고통**이다.

### 🤖 Modeling Lead 보강

> **[Model-Product Fit]**
>
> 에이전트에게 "settings.yaml에 새 원두를 추가해줘"라고 말하면 에이전트가 YAML을 자동 편집할 수 있다. **에이전트를 설정 변경 도구로도 활용**하면 비개발자 YAML 편집 문제가 해결된다.

### ⚙️ Tech Lead 반론

> **[Security & Reliability]**
>
> 에이전트가 설정 파일을 수정하면 **설정 변경 추적**이 어렵고, 실수로 기존 데이터를 훼손할 위험이 있다. 변경 시 **백업 자동 생성** + **변경 확인(Dry-run)** 출력이 필요하다.

### ✅ 결정: **수용 (가이드 형태)**

- SKILL.md에 **"에이전트를 통한 설정 변경 가이드"** 추가:
  - `"에티오피아 하라를 원두 목록에 추가해줘"` → 에이전트가 settings.yaml 변경
  - 변경 전 **Dry-run (변경 미리보기)** 출력 필수
  - 변경 시 **이전 버전 자동 백업** (`settings.yaml.bak`)
- 설정 변경은 **관리자 명시적 요청 시에만** 수행 (주문 처리 중 자동 변경 금지)

---

## Round 8: 데이터 정합성 — 시트와 settings 간 불일치 시나리오

### ⚙️ Tech Lead 비판

> **[Reliability: DATA INTEGRITY]**
>
> 시트와 settings.yaml 사이의 **정합성 관리**가 부족하다:
>
> 1. **매장 코드 불일치**: settings에 `GN`(강남점)으로 등록했는데, 시트에 `KN`으로 입력하면? 매핑 실패 → 데이터 누락.
> 2. **Sheets URL 변경**: Google Sheets URL이 바뀌면(시트 재생성 등), settings를 수동 업데이트해야 한다. 깜빡하면 접근 불가.
> 3. **원두 코드 변경**: settings에서 `ETH-YRG`를 `ETH-YG`로 오타 수정하면, 과거 시트 데이터와 매핑이 깨진다.

### 🤖 Modeling Lead 보강

> **[Eval & Safety]**
>
> 이것은 **데이터 유효성 검증(Schema Validation)**의 영역이다. 에이전트 실행 시작 시 settings와 실제 시트 데이터 간 **사전 정합성 체크**를 수행해야 한다:
>
> - 시트의 매장코드가 settings.stores에 존재하는지
> - 시트의 원두코드가 settings.beans에 존재하는지 (이미 있지만, 매장코드는 없음)

### 📋 Product Lead 중재

> **[KPI Definition]**
>
> "실행 전 헬스체크" 개념으로, 에이전트가 데이터 수집 전에 **settings.yaml 자체 유효성** + **Sheets 접근 가능성**을 먼저 확인하는 단계를 추가하면 좋겠다. 빠르게 실패(Fail-fast)하면 관리자가 시간을 낭비하지 않는다.

### ✅ 결정: **수용 — 즉시 반영**

- 에이전트 실행 흐름에 **"Step 0: 사전 헬스체크"** 단계 추가:
  1. settings.yaml 구문 검증
  2. 모든 매장 Sheets URL 접근 가능성 확인 (빠른 ping)
  3. 매장코드·원두코드 기본 매핑 확인
- 헬스체크 실패 시 **즉시 중단** + 실패 원인 안내 (데이터 수집 전에 종료)

---

## Round 9: 비용-가치 모델링 — enable_cost_report의 한계

### 🤖 Modeling Lead 비판

> **[Model-Product Fit: SHALLOW]**
>
> `enable_cost_report`가 단순히 `cost_per_kg × 수량`의 곱셈이라면, 이것은 **AI가 할 일이 아니라 엑셀 수식**이다. AI 모델링이 개입할 여지가 있다면:
>
> 1. **동적 원가 반영**: 생두 시세가 변동하는데, settings에 고정 원가를 넣으면 한 달 뒤 의미 없는 숫자가 된다. **원가 업데이트 전략**이 없다.
> 2. **마진 분석 부재**: 원가만 보여주면 반쪽짜리. 판매가 대비 마진율, 원두별 수익성 분석 등 **경영 판단에 도움되는 인사이트**가 없다.
> 3. **예측 모델 없음**: 과거 주문 패턴 기반 **다음 주 예상 수요 예측**이 있어야 생두 발주 계획을 세울 수 있다. 이것이야말로 **AI가 가치를 제공하는 영역**이다.

### 📋 Product Lead 반론

> **[10x Value Check / KPI]**
>
> 수요 예측은 **킬러 피처 후보**다. 그러나 v1에는 과거 데이터가 없다:
>
> 1. v1에서 **데이터를 축적**하고
> 2. v2에서 "지난 3개월 주문 패턴 → 다음 주 예상 수요" 기능을 추가
> 3. 이때 비로소 **Model-Product Fit이 성립**한다
>
> 원가 업데이트는 현실적으로 관리자가 **월 1회** 시세를 확인해서 settings를 업데이트하면 충분하다.

### ⚙️ Tech Lead 보강

> **[Tech Debt Assessment]**
>
> v2의 수요 예측을 위해 **지금부터 데이터를 구조화해서 저장**해야 한다. 리포트를 Markdown으로만 남기면 파싱이 어렵다. **리포트 데이터를 별도 CSV/JSON으로도 저장**하는 옵션이 필요하다.

### ✅ 결정: **부분 수용**

- SKILL.md에 **원가 업데이트 주기 가이드** 추가: "월 1회 시세 확인 후 cost_per_kg 업데이트 권장"
- v1.5에서 리포트 데이터를 **CSV 부출력(export)** 옵션 추가 (v2 수요 예측용 데이터 축적)
- v2 로드맵에 **"수요 예측 모델"** 추가 — 과거 주문 CSV 기반 다음 주 예상 수요 생성

---

## Round 10: 전체 시스템 아키텍처 재평가 — v4 설계의 최종 판정

### 🤖 Modeling Lead 최종 평가

> **[AI 관점 종합 평가]**
>
> | 항목 | 평가 | 근거 |
> |------|------|------|
> | Model-Product Fit | 🟡 **조건부 적합** | 코드 실행 병행 시 적합. 순수 LLM 집계는 부적합 |
> | Inference Efficiency | 🟡 **수용 가능** | 일 1회 실행, 3분 이내면 비즈니스에 충분 |
> | Eval & Safety | 🟠 **개선 필요** | 가드레일·형식 고정·헬스체크 추가로 개선됨. 정량 평가는 v2 |
>
> **핵심 조언**: 이 시스템에서 AI의 진짜 가치는 "계산"이 아니라 **"비정형 데이터의 유연한 해석"과 "자연어 인터페이스"**다. 계산은 코드에, 해석은 AI에 맡기는 하이브리드가 최적해다.

### 📋 Product Lead 최종 평가

> **[비즈니스 관점 종합 평가]**
>
> | 항목 | 평가 | 근거 |
> |------|------|------|
> | 10x Value | ✅ **달성** | 수작업 60분 → 3분, 비개발자 접근성 |
> | User Flow | 🟡 **개선됨** | 헬스체크·가드레일·에러 UX 반영으로 이탈 감소 |
> | KPI Readiness | 🟡 **기초 수준** | 경고 건수 추적은 가능. 정량 KPI는 v2 |
>
> **핵심 조언**: v1의 성공 기준은 "완벽한 시스템"이 아니라 **"관리자가 매일 쓰는 도구가 되었는가"**다.

### ⚙️ Tech Lead 최종 평가

> **[기술 관점 종합 평가]**
>
> | 항목 | 평가 | 근거 |
> |------|------|------|
> | Bottleneck | 🟡 **관리 가능** | 5매장까지 O(n) 선형이지만 허용 범위 |
> | Security | 🟡 **개선됨** | 전용 계정·읽기 전용·헬스체크 추가 |
> | Tech Debt | 🟠 **감시 필요** | settings.yaml 비대화 + 스크립트 0개 리스크는 v1.5에서 대응 예정 |
>
> **핵심 조언**: 가장 긴급한 기술 과제는 **"헬스체크 + 코드 실행 분리"**다. 이 두 가지만 반영하면 v1의 안정성은 충분하다.

### ✅ 최종 합의

3개 에이전트 모두 **v4 설계를 조건부 승인**한다. 조건:
1. SKILL.md에 코드 실행 분리 + 프롬프트 엔지니어링 원칙 반영 (Round 1, 4)
2. 사전 헬스체크 단계 추가 (Round 8)
3. 보안 가이드 + 읽기 전용 원칙 (Round 5)

---

## 📊 전체 판정 요약 (10 Rounds)

| # | 주제 | 주도 | 판정 | 핵심 결정 |
|---|------|------|------|----------|
| 1 | LLM 집계 적합성 | 🤖 ML | 🤖 **ML 부분 승리** | 코드 실행 분리 원칙 추가 |
| 2 | 교차검증 평가 지표 | 🤖 ML | ⚖️ **부분 수용** | 경고 건수 추적 (v1), 정량 지표 (v2) |
| 3 | 브라우저 순회 성능 | ⚙️ TL | ⚙️ **TL 승리** | 매장별 순차 + 중간 집계 전략 |
| 4 | SKILL.md 프롬프트 설계 | 🤖 ML | 🤖 **ML 승리** | 역할·Few-shot·가드레일 추가 |
| 5 | Google 계정 보안 | ⚙️ TL | ⚖️ **합의** | 전용 계정 + 읽기 전용 + API 전환 (v2) |
| 6 | 리포트 일관성 | 🤖 ML | 🤖 **ML 승리** | 출력 형식 고정 + 형식 검증 |
| 7 | 설정 변경 UX | 📋 PL | 📋 **PL 승리** | 에이전트 통한 설정 변경 지원 |
| 8 | 데이터 정합성 | ⚙️ TL | ⚙️ **TL 승리** | 사전 헬스체크 단계 추가 |
| 9 | 비용-가치 모델링 | 🤖 ML | ⚖️ **부분 수용** | v2에 수요 예측, v1.5에 CSV export |
| 10 | 최종 종합 평가 | 전원 | ✅ **조건부 승인** | 3개 핵심 조건 충족 시 v4 확정 |

### 승패 집계

| | 승리 | 부분 수용 | 합의 |
|---|------|----------|------|
| 🤖 **Modeling Lead** | 3회 (R1, R4, R6) | 2회 (R2, R9) | 1회 (R5) |
| 📋 **Product Lead** | 1회 (R7) | — | — |
| ⚙️ **Tech Lead** | 2회 (R3, R8) | — | 1회 (R5) |

---

## 🎯 서비스 스펙 반영 사항

### 즉시 반영 (v1)

| # | 항목 | 출처 | 내용 |
|---|------|------|------|
| 1 | 코드 실행 분리 원칙 | R1 | 산술 연산은 코드로, 해석·문장 생성은 LLM으로 |
| 2 | SKILL.md 프롬프트 강화 | R4 | 에이전트 역할 정의 + Few-shot 예시 + 단계별 처리 지시 |
| 3 | 가드레일 규칙 | R4 | 해석 불확실 시 해당 행 건너뛰기 + 경고 |
| 4 | 보안 가이드 | R5 | 전용 계정 사용 + 읽기 전용 원칙 + `read_only: true` |
| 5 | 출력 형식 고정 | R6 | 템플릿 구조 변경 금지 + 숫자 포맷 규칙 |
| 6 | 사전 헬스체크 | R8 | Step 0: YAML 검증 → Sheets 접근 → 코드 매핑 확인 |
| 7 | 순차 처리 전략 | R3 | 매장별 읽기 → 중간 집계 → 최종 합산 |
| 8 | 에이전트 설정 변경 | R7 | Dry-run + 백업 생성 후 settings.yaml 변경 |
| 9 | 경고 건수 요약 | R2 | 리포트 메타데이터에 경고 발생 건수 추가 |
| 10 | 원가 업데이트 가이드 | R9 | 월 1회 시세 확인 권장 |

### settings.yaml 추가

```yaml
read_only: true              # [R5] 에이전트 읽기 전용 원칙 플래그
```

### 교차검증 항목 추가 (14 → 15)

| # | 검증 항목 | 출처 | 설명 |
|---|-----------|------|------|
| 15 | **리포트 형식 검증** | R6 | 컬럼명·섹션 순서가 템플릿과 일치하는지 |

### v1.5 / v2 로드맵 추가

| 시점 | 항목 | 출처 |
|------|------|------|
| v1.5 | 리포트 데이터 CSV 부출력 (수요 예측용 데이터 축적) | R9 |
| v1.5 | 매장별 처리 시간 메타데이터 | R3 |
| v1.5 | 주간 품질 요약 자동 생성 | R2 |
| v2 | 수요 예측 모델 (과거 주문 CSV 기반) | R9 |
| v2 | Google Sheets API + 서비스 계정 (최소 권한) | R5 |
